{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import nltk\n",
    "except ModuleNotFoundError:\n",
    "    !pip install nltk\n",
    "    \n",
    "try:\n",
    "    import numpy as np\n",
    "except ModuleNotFoundError:\n",
    "    !pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to C:\\Users\\Suraksha\n",
      "[nltk_data]     Aithal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\reuters.zip.\n"
     ]
    }
   ],
   "source": [
    "## This code downloads the required packages.\n",
    "\n",
    "nltk_packages = [\n",
    "    (\"reuters\", \"corpora/reuters.zip\")\n",
    "]\n",
    "\n",
    "for pid, fid in nltk_packages:\n",
    "    try:\n",
    "        nltk.data.find(fid)\n",
    "    except LookupError:\n",
    "        nltk.download(pid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import reuters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up train/test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_documents, train_categories = zip(*[(reuters.raw(i), reuters.categories(i)) for i in reuters.fileids() if i.startswith('training/')])\n",
    "test_documents, test_categories = zip(*[(reuters.raw(i), reuters.categories(i)) for i in reuters.fileids() if i.startswith('test/')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_categories = sorted(list(set(reuters.categories())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenizing the documents and removing the stopwords\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "train_tokens = [nltk.word_tokenize(text) for text in train_documents]\n",
    "test_tokens = [nltk.word_tokenize(text) for text in test_documents]\n",
    "\n",
    "\n",
    "\n",
    "#converting the words in train_Set to lower case\n",
    "\n",
    "\n",
    "all_words = []\n",
    "for w in train_tokens:\n",
    "    for i in w:\n",
    "        all_words.append(i.lower())\n",
    " \n",
    "\n",
    "    \n",
    "\n",
    "#converting the words in test_set to lower case\n",
    "all_words_test_set = []\n",
    "for w in test_tokens:\n",
    "    for i in w:\n",
    "        all_words_test_set.append(i.lower())\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " import string\n",
    "\n",
    "\n",
    "#removing the stop_Words in train_set\n",
    "\n",
    "\n",
    "filtered_sentence = []\n",
    "for w in all_words:\n",
    "        if w not in stop_words:\n",
    "            filtered_sentence.append(w)\n",
    "        \n",
    "\n",
    "#removing the stop_words in test_set\n",
    "filtered_sentence_test = []\n",
    "for i in all_words_test_set:\n",
    "        if i not in stop_words:\n",
    "            filtered_sentence_test.append(i)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# removing punctuation from training sets\n",
    "\n",
    "no_punc=[]\n",
    "Punctuation = ['.',',','\"','?',';',':','}','{','(',')','!','@','#',\"''\",'\"\"',\n",
    "                   \"``\",\"'s\",\"&\",\">\",\"<\"]\n",
    "for i in filtered_sentence:\n",
    "    if i not in Punctuation:\n",
    "        no_punc.append(i)\n",
    "        \n",
    "\n",
    "\n",
    "# removing punctuation from test set\n",
    "no_punctuation=[]\n",
    "Punctuation = ['.',',','\"','?',';',':','}','{','(',')','!','@','#',\"''\",'\"\"',\n",
    "                   \"``\",\"'s\",\"&\",\">\",\"<\"]\n",
    "for i in filtered_sentence_test:\n",
    "    if i not in Punctuation:\n",
    "        no_punctuation.append(i)\n",
    "        \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmatizing the train_set\n",
    "\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized =[]\n",
    "lemmatized = [lemmatizer.lemmatize(w) for w in no_punc]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#lemmatizing the test_Set\n",
    "lemmatized_test_set =[]\n",
    "lemmatized_test_set = [lemmatizer.lemmatize(w) for w in no_punctuation]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_feat=nltk.FreqDist(lemmatized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature extraction\n",
    "\n",
    "\n",
    "word_features = [x for (x,y) in word_feat.most_common(2500)]\n",
    "lemmas = []\n",
    "for w in all_categories:\n",
    "    lemmas = lemmatizer.lemmatize(w)\n",
    "    word_features.append(lemmas)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature vector formation\n",
    "\n",
    "X_train = [[1 if w in tokens else 0 for w in word_features] for tokens in train_tokens]\n",
    "X_test  = [[1 if w in tokens else 0 for w in word_features] for tokens in test_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the all categories from the MultiLabelBinarizer:\n",
      "acq, alum, barley, bop, carcass, castor-oil, cocoa, coconut, coconut-oil, coffee, copper, copra-cake, corn, cotton, cotton-oil, cpi, cpu, crude, dfl, dlr, dmk, earn, fuel, gas, gnp, gold, grain, groundnut, groundnut-oil, heat, hog, housing, income, instal-debt, interest, ipi, iron-steel, jet, jobs, l-cattle, lead, lei, lin-oil, livestock, lumber, meal-feed, money-fx, money-supply, naphtha, nat-gas, nickel, nkr, nzdlr, oat, oilseed, orange, palladium, palm-oil, palmkernel, pet-chem, platinum, potato, propane, rand, rape-oil, rapeseed, reserves, retail, rice, rubber, rye, ship, silver, sorghum, soy-meal, soy-oil, soybean, strategic-metal, sugar, sun-meal, sun-oil, sunseed, tea, tin, trade, veg-oil, wheat, wpi, yen, zinc\n",
      "\n",
      "Categories: ['acq', 'trade']\n",
      "Vector: [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "\n",
      "The 0th entry represents the label 'acq'\n"
     ]
    }
   ],
   "source": [
    "# Multi-label binarizing\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit(train_categories + test_categories)\n",
    "\n",
    "print(\"These are the all categories from the MultiLabelBinarizer:\\n{}\".format(\", \".join(mlb.classes_)))\n",
    "\n",
    "example = mlb.transform([train_categories[6]])[0]\n",
    "print(\"\\nCategories: {}\\nVector: {}\".format(train_categories[6], example))\n",
    "print(\"\\nThe 0th entry represents the label '{}'\".format(mlb.classes_[0]))\n",
    "\n",
    "\n",
    "y_train = mlb.transform(train_categories)\n",
    "y_test  = mlb.transform(test_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifier training\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = OrderedDict()\n",
    "\n",
    "for i, category in enumerate(all_categories):\n",
    "    clf = DecisionTreeClassifier()\n",
    "    \n",
    "    # We train each classifier individually, so we must use\n",
    "    # only 0 or 1 as y_train.\n",
    "    y_train_clf = [yt[i] for yt in y_train]\n",
    "    \n",
    "    # .fit() will train the model with the training data\n",
    "    clf.fit(X_train, y_train_clf)\n",
    "    \n",
    "    clfs[category] = clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifer evaluation\n",
    "\n",
    "y_pred = np.zeros((len(y_test), len(all_categories)))\n",
    "\n",
    "for i, (cat, clf) in enumerate(clfs.items()):\n",
    "    y_pred[:, i] = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.6101\n",
      "Precision: 0.7421\n",
      "Recall   : 0.7118\n",
      "F1-Score : 0.7267\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy : {:.4f}\".format(metrics.accuracy_score(y_test, y_pred)))\n",
    "print(\"Precision: {:.4f}\".format(metrics.precision_score(y_test, y_pred, average='micro')))\n",
    "print(\"Recall   : {:.4f}\".format(metrics.recall_score(y_test, y_pred, average='micro')))\n",
    "print(\"F1-Score : {:.4f}\".format(metrics.f1_score(y_test, y_pred, average='micro')))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "            acq       0.84      0.75      0.79       719\n",
      "           alum       0.55      0.48      0.51        23\n",
      "         barley       0.60      0.43      0.50        14\n",
      "            bop       0.61      0.47      0.53        30\n",
      "        carcass       0.48      0.56      0.51        18\n",
      "     castor-oil       0.00      0.00      0.00         1\n",
      "          cocoa       0.60      1.00      0.75        18\n",
      "        coconut       0.50      0.50      0.50         2\n",
      "    coconut-oil       0.00      0.00      0.00         3\n",
      "         coffee       0.77      0.86      0.81        28\n",
      "         copper       0.80      0.67      0.73        18\n",
      "     copra-cake       0.00      0.00      0.00         1\n",
      "           corn       0.71      0.73      0.72        56\n",
      "         cotton       0.78      0.70      0.74        20\n",
      "     cotton-oil       0.00      0.00      0.00         2\n",
      "            cpi       0.37      0.36      0.36        28\n",
      "            cpu       0.00      0.00      0.00         1\n",
      "          crude       0.74      0.76      0.75       189\n",
      "            dfl       0.00      0.00      0.00         1\n",
      "            dlr       0.33      0.50      0.40        44\n",
      "            dmk       0.00      0.00      0.00         4\n",
      "           earn       0.90      0.93      0.92      1087\n",
      "           fuel       0.50      0.30      0.37        10\n",
      "            gas       0.44      0.24      0.31        17\n",
      "            gnp       0.32      0.23      0.27        35\n",
      "           gold       0.63      0.63      0.63        30\n",
      "          grain       0.82      0.76      0.79       149\n",
      "      groundnut       0.00      0.00      0.00         4\n",
      "  groundnut-oil       0.00      0.00      0.00         1\n",
      "           heat       0.80      0.80      0.80         5\n",
      "            hog       0.57      0.67      0.62         6\n",
      "        housing       0.40      0.50      0.44         4\n",
      "         income       0.00      0.00      0.00         7\n",
      "    instal-debt       0.00      0.00      0.00         1\n",
      "       interest       0.59      0.58      0.59       131\n",
      "            ipi       0.57      0.67      0.62        12\n",
      "     iron-steel       0.75      0.21      0.33        14\n",
      "            jet       0.00      0.00      0.00         1\n",
      "           jobs       0.85      0.52      0.65        21\n",
      "       l-cattle       0.33      0.50      0.40         2\n",
      "           lead       0.73      0.57      0.64        14\n",
      "            lei       0.75      1.00      0.86         3\n",
      "        lin-oil       0.00      0.00      0.00         1\n",
      "      livestock       0.65      0.62      0.64        24\n",
      "         lumber       0.50      0.17      0.25         6\n",
      "      meal-feed       0.69      0.58      0.63        19\n",
      "       money-fx       0.53      0.51      0.52       179\n",
      "   money-supply       0.32      0.35      0.33        34\n",
      "        naphtha       0.00      0.00      0.00         4\n",
      "        nat-gas       0.55      0.53      0.54        30\n",
      "         nickel       0.25      1.00      0.40         1\n",
      "            nkr       0.00      0.00      0.00         2\n",
      "          nzdlr       0.00      0.00      0.00         2\n",
      "            oat       0.20      0.17      0.18         6\n",
      "        oilseed       0.56      0.62      0.59        47\n",
      "         orange       0.88      0.64      0.74        11\n",
      "      palladium       0.00      0.00      0.00         1\n",
      "       palm-oil       0.82      0.90      0.86        10\n",
      "     palmkernel       0.00      0.00      0.00         1\n",
      "       pet-chem       0.33      0.17      0.22        12\n",
      "       platinum       1.00      0.29      0.44         7\n",
      "         potato       0.67      0.67      0.67         3\n",
      "        propane       1.00      0.33      0.50         3\n",
      "           rand       0.00      0.00      0.00         1\n",
      "       rape-oil       0.00      0.00      0.00         3\n",
      "       rapeseed       0.78      0.78      0.78         9\n",
      "       reserves       0.24      0.22      0.23        18\n",
      "         retail       0.00      0.00      0.00         2\n",
      "           rice       0.77      0.71      0.74        24\n",
      "         rubber       0.65      0.92      0.76        12\n",
      "            rye       0.00      0.00      0.00         1\n",
      "           ship       0.73      0.57      0.64        89\n",
      "         silver       0.20      0.12      0.15         8\n",
      "        sorghum       0.60      0.60      0.60        10\n",
      "       soy-meal       0.38      0.23      0.29        13\n",
      "        soy-oil       0.21      0.27      0.24        11\n",
      "        soybean       0.52      0.48      0.50        33\n",
      "strategic-metal       0.00      0.00      0.00        11\n",
      "          sugar       0.91      0.86      0.89        36\n",
      "       sun-meal       0.00      0.00      0.00         1\n",
      "        sun-oil       0.00      0.00      0.00         2\n",
      "        sunseed       0.17      0.20      0.18         5\n",
      "            tea       1.00      1.00      1.00         4\n",
      "            tin       0.75      0.50      0.60        12\n",
      "          trade       0.54      0.52      0.53       117\n",
      "        veg-oil       0.53      0.51      0.52        37\n",
      "          wheat       0.74      0.76      0.75        71\n",
      "            wpi       0.80      0.40      0.53        10\n",
      "            yen       0.29      0.29      0.29        14\n",
      "           zinc       0.79      0.85      0.81        13\n",
      "\n",
      "    avg / total       0.74      0.71      0.72      3744\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Suraksha Aithal\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_true=y_test, y_pred=y_pred, target_names=mlb.classes_))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example text: This example text should cover coconuts. But we chose bad features, so we have wrong labels.\n",
      "Example labels: [('coconut', 'oilseed')]\n"
     ]
    }
   ],
   "source": [
    "#pipeline\n",
    "\n",
    "example_text = \"This example text should cover coconuts. But we chose bad features, so we have wrong labels.\"\n",
    "\n",
    "\n",
    "example_tokens = nltk.word_tokenize(example_text)\n",
    "\n",
    "filtered_sentence = []\n",
    "for w in example_tokens:\n",
    "        if w not in stop_words:\n",
    "            filtered_sentence.append(w)\n",
    "\n",
    "no_punc=[]\n",
    "Punctuation = ['.',',','\"','?',';',':','}','{','(',')','!','@','#',\"''\",'\"\"',\"``\",\"'s\",\"&\",\">\",\"<\"]\n",
    "for i in filtered_sentence:\n",
    "    if i not in Punctuation:\n",
    "        no_punc.append(i)\n",
    "\n",
    "\n",
    "lemma = []\n",
    "for w in no_punc:\n",
    "    w = lemmatizer.lemmatize(w)\n",
    "    lemma.append(w)\n",
    "\n",
    "    \n",
    "example_features = [[1 if w in lemma else 0 for w in word_features]]\n",
    "\n",
    "example_preds = [clf.predict(example_features)[0] for clf in clfs.values()]\n",
    "\n",
    "example_labels = mlb.inverse_transform(np.array([example_preds]))\n",
    "\n",
    "print(\"Example text: {}\".format(example_text))\n",
    "print(\"Example labels: {}\".format(example_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
